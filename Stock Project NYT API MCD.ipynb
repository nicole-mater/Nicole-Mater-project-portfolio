{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20c97916-180c-49b0-89d3-4c8b0361d31b",
   "metadata": {},
   "source": [
    "## McDonalds NYT Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b6669a-8f1e-4d3d-972d-7f4c70566789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import time\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca77fd4-fe8d-47b2-854b-a0acc41cc92c",
   "metadata": {},
   "source": [
    "### Requesting from the NYT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbe186b3-2f68-447c-b8bd-987de206294d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished year 2020: no more articles at page 32\n",
      "Finished year 2021: no more articles at page 30\n",
      "Finished year 2022: no more articles at page 36\n",
      "Finished year 2023: no more articles at page 24\n",
      "Finished year 2024: no more articles at page 36\n",
      "Finished year 2025: no more articles at page 24\n"
     ]
    }
   ],
   "source": [
    "# pull all articles relevant to McDonald's in our time frame\n",
    "\n",
    "years = range(2020, 2026) # Nov-15-2020 start date to match Google Trends data\n",
    "allresults_mcd = []\n",
    "baseurl=\"https://api.nytimes.com/svc/search/v2/articlesearch.json?\"\n",
    "apikey=\"GGCXEfbqfbBKk5Aii36FMKPK6De5udGe\" # udpate API key for new users\n",
    "\n",
    "# for loop to iterate through each year in our time frame\n",
    "for year in years:\n",
    "    begin = f\"{year}0101\"\n",
    "    end   = f\"{year}1231\"\n",
    "\n",
    "    page = 0\n",
    "\n",
    "    while True:\n",
    "        pa2 = {\"api-key\":apikey,\n",
    "            \"q\": '\"McDonald\\'s\"',\n",
    "            \"begin_date\": begin,\n",
    "            \"end_date\": end,\n",
    "            \"page\": page}\n",
    "    \n",
    "        mcd_url = baseurl + urllib.parse.urlencode(pa2)\n",
    "        request2 = urllib.request.urlopen(mcd_url).read()\n",
    "        resd2 = json.loads(request2)\n",
    "    \n",
    "        response_block2 = resd2.get(\"response\")\n",
    "\n",
    "        \n",
    "        # failsafe for API error\n",
    "        if response_block2 is None:\n",
    "            print(f\"API returned no response for year {year}, page {page}. Retrying...\")\n",
    "            time.sleep(18)\n",
    "            continue   # try again\n",
    "    \n",
    "        docs2 = response_block2.get(\"docs\")\n",
    "        \n",
    "        # indicates end of articles\n",
    "        if docs2 is None or len(docs2) == 0:\n",
    "            print(f\"Finished year {year}: no more articles at page {page}\")\n",
    "            break\n",
    "    \n",
    "        # collect the objects of interest\n",
    "        for doc in docs2:\n",
    "            allresults_mcd.append({\n",
    "                \"headline\"         : doc.get('headline', {}).get('main', ''),\n",
    "                \"abstract\"         : doc.get('abstract', ''),\n",
    "                \"publication_date\" : doc.get('pub_date', ''),\n",
    "                \"document_type\"    : doc.get('document_type', ''),\n",
    "                \"section_name\"     : doc.get('section_name', ''),\n",
    "                \"subsection_name\"  : doc.get('subsection_name', '')\n",
    "            })\n",
    "       \n",
    "        page += 1  # scraping every page of articles\n",
    "        time.sleep(18)  # time delay so we don't hit the article limit\n",
    "        \n",
    "    \n",
    "mcd_df = pd.DataFrame(allresults_mcd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80cd8ac-d375-4846-b3e2-b8f1b5f3a021",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mcd_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mcd_df \u001b[38;5;241m=\u001b[39m \u001b[43mmcd_df\u001b[49m[\n\u001b[1;32m      2\u001b[0m     (mcd_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdocument_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marticle\u001b[39m\u001b[38;5;124m\"\u001b[39m) ] \u001b[38;5;66;03m# filtering the results down to article types only\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mcd_df' is not defined"
     ]
    }
   ],
   "source": [
    "mcd_df = mcd_df[\n",
    "    (mcd_df['document_type'] == \"article\") ] # filtering the results down to article types only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa050f3-902e-45ac-82f6-f68780937772",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd_df = mcd_df[\n",
    "    mcd_df['headline'].str.contains(\"McCafé\", case=False, na=False) |\n",
    "    mcd_df['abstract'].str.contains(\"McCafé\", case=False, na=False) |\n",
    "    mcd_df['headline'].str.contains(\"McDonald’s\", case=False, na=False) |\n",
    "    mcd_df['abstract'].str.contains(\"McDonald’s\", case=False, na=False)]\n",
    "# filtering the output so the headline or abstract include the company name\n",
    "# we also decided to include McCafe for relevance to coffee\n",
    "\n",
    "mcd_df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2ba246-911f-49ab-a38a-55edd51c0b5a",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "506bb6a7-c29c-4aa4-9662-53b4793ba1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# combine the headline and abstract into one field for sentiment analysis\n",
    "mcd_df['text'] = mcd_df['headline'] + \" \" + mcd_df['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a61e769-e6e6-4a77-b826-f78f4f84806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_pos2 = []\n",
    "sent_neg2 = []\n",
    "sent_neu2 = []\n",
    "sent_comp2 = []\n",
    "corpus2 = mcd_df['text']\n",
    "\n",
    "# iterate through each sentence in corpus\n",
    "for article in corpus2:\n",
    "    \n",
    "    # analyze the sentiment. ss is a dictionary\n",
    "    ss = sia.polarity_scores(article)\n",
    "\n",
    "    # append and store these sentiment scores into a list\n",
    "    sent_pos2.append(ss['pos'])\n",
    "    sent_neg2.append(ss['neg'])\n",
    "    sent_neu2.append(ss['neu'])\n",
    "    sent_comp2.append(ss['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd43fcb8-7b35-4a87-9904-64ac9a6fb6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the list to the dataframe as column using assign(column_name = data)\n",
    "mcd_df = mcd_df.assign(article_pos = sent_pos2)\n",
    "mcd_df = mcd_df.assign(article_neg = sent_neg2)\n",
    "mcd_df = mcd_df.assign(article_neu = sent_neu2)\n",
    "mcd_df = mcd_df.assign(article_comp = sent_comp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f4449-a3a9-4f1e-9fd2-e3e53e982cd2",
   "metadata": {},
   "source": [
    "### Summarizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70aec6a9-7637-441f-94de-8a48d0e84fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcd_df = mcd_df.copy()\n",
    "mcd_df['publication_date'] = pd.to_datetime(mcd_df['publication_date'])\n",
    "\n",
    "# find the Friday of the week for each publication date\n",
    "mcd_df['fiscal_week'] = mcd_df['publication_date'] + pd.offsets.Week(weekday=4)\n",
    "mcd_df['fiscal_week'] = mcd_df['fiscal_week'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "708d8017-48ed-4b94-846f-4add2cf327fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_df_mcd = (\n",
    "    mcd_df.groupby('fiscal_week')\n",
    "          .agg(\n",
    "               article_count = ('text', 'count'),\n",
    "              pos_sentiment  = ('article_pos', 'sum'),\n",
    "              neg_sentiment  = ('article_neg', 'sum'),\n",
    "              neu_sentiment  = ('article_neu', 'sum'),\n",
    "              comp_sentiment = ('article_comp', 'mean'),\n",
    "          )\n",
    "          .reset_index()\n",
    ")\n",
    "# group the rest of the columns by summing or averaging the values for the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "131865f3-c655-434e-97a7-bff4f7cc7851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ratios to analyze article sentiment\n",
    "# total\n",
    "weekly_df_mcd['total_sent'] = weekly_df_mcd['pos_sentiment'] + weekly_df_mcd['neg_sentiment'] + weekly_df_mcd['neu_sentiment']\n",
    "# ratios\n",
    "weekly_df_mcd['pos_ratio'] = weekly_df_mcd['pos_sentiment'] / weekly_df_mcd['total_sent']\n",
    "weekly_df_mcd['neg_ratio'] = weekly_df_mcd['neg_sentiment'] / weekly_df_mcd['total_sent']\n",
    "\n",
    "weekly_df_mcd = weekly_df_mcd.drop(columns=['total_sent', 'pos_sentiment', 'neg_sentiment', 'neu_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87b6c79d-1875-48ed-acc6-2f4fe50ee41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of     fiscal_week  article_count  comp_sentiment  pos_ratio  neg_ratio\n",
       "0    2020-01-03              2        0.246950   0.056528   0.023012\n",
       "1    2020-01-10              5       -0.012160   0.070614   0.091018\n",
       "2    2020-01-17             11       -0.101209   0.052545   0.087273\n",
       "3    2020-01-24              4       -0.136100   0.055750   0.099000\n",
       "4    2020-01-31              8       -0.240062   0.047756   0.091261\n",
       "..          ...            ...             ...        ...        ...\n",
       "301  2025-10-31              1        0.557400   0.286000   0.000000\n",
       "302  2025-11-07              8       -0.016400   0.081645   0.087647\n",
       "303  2025-11-14              4       -0.147550   0.107223   0.124219\n",
       "304  2025-11-21              5       -0.054300   0.051400   0.064600\n",
       "305  2025-11-28              4       -0.758425   0.012750   0.210500\n",
       "\n",
       "[306 rows x 5 columns]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final dataset\n",
    "weekly_df_mcd.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a0d2f43-d589-4059-94c3-6ab783dd4331",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_df_mcd.to_csv(\"mcd_nyt_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
